@article{Devecioglu_2024,
  title    = {Blind Underwater Image Restoration using Co-Operational Regressor Networks},
  year     = {2024},
  author   = {Ozer Can Devecioglu and S. Kiranyaz and T. Ince and M. Gabbouj},
  doi      = {10.48550/arxiv.2412.03995},
  pmid     = {null},
  pmcid    = {null},
  mag_id   = {null},
  journal  = {arXiv.org},
  abstract = {The exploration of underwater environments is essential for applications such as biological research, archaeology, and infrastructure maintenanceHowever, underwater imaging is challenging due to the waters unique properties, including scattering, absorption, color distortion, and reduced visibility. To address such visual degradations, a variety of approaches have been proposed covering from basic signal processing methods to deep learning models; however, none of them has proven to be consistently successful. In this paper, we propose a novel machine learning model, Co-Operational Regressor Networks (CoRe-Nets), designed to achieve the best possible underwater image restoration. A CoRe-Net consists of two co-operating networks: the Apprentice Regressor (AR), responsible for image transformation, and the Master Regressor (MR), which evaluates the Peak Signal-to-Noise Ratio (PSNR) of the images generated by the AR and feeds it back to AR. CoRe-Nets are built on Self-Organized Operational Neural Networks (Self-ONNs), which offer a superior learning capability by modulating nonlinearity in kernel transformations. The effectiveness of the proposed model is demonstrated on the benchmark Large Scale Underwater Image (LSUI) dataset. Leveraging the joint learning capabilities of the two cooperating networks, the proposed model achieves the state-of-art restoration performance with significantly reduced computational complexity and often presents such results that can even surpass the visual quality of the ground truth with a 2-pass application. Our results and the optimized PyTorch implementation of the proposed approach are now publicly shared on GitHub.}
}
@article{Ma_2022,
  title    = {A Wavelet-Based Dual-Stream Network for Underwater Image Enhancement},
  year     = {2022},
  author   = {Zhen Ma and Ziyin Ma and Chang-Hwan Oh and Changjae Oh},
  doi      = {10.1109/icassp43922.2022.9747781},
  pmid     = {null},
  pmcid    = {null},
  mag_id   = {4225309680},
  journal  = {IEEE International Conference on Acoustics, Speech, and Signal Processing},
  abstract = {We present a wavelet-based dual-stream network that addresses color cast and blurry details in underwater images. We handle these artifacts separately by decomposing an input image into multiple frequency bands using discrete wavelet transform, which generates the downsampled structure image and detail images. These sub-band images are used as input to our dual-stream network that incorporates two sub-networks: the multi-color space fusion network and the detail enhancement network. The multi-color space fusion network takes the decomposed structure image as input and estimates the color corrected output by employing the feature representations from diverse color spaces of the input. The detail enhancement network addresses the blurriness of the original underwater image by improving the image details from high-frequency sub-bands. We validate the proposed method on both real-world and synthetic underwater datasets and show the effectiveness of our model in color correction and blur removal with low computational complexity.}
}
@article{Li_2020,
  title    = {Color Correction Based on CFA and Enhancement Based on Retinex With Dense Pixels for Underwater Images},
  year     = {2020},
  author   = {Changli Li and Changli Li and Shiqiang Tang and Shiqiang Tang and Hon Keung Kwan and Hon Keung Kwan and Jingwen Yan and Jingwen Yan and Jingwen Yan and Teng Zhou and Teng Zhou},
  doi      = {10.1109/access.2020.3019354},
  pmid     = {null},
  pmcid    = {null},
  mag_id   = {3080549542},
  journal  = {IEEE Access},
  abstract = {Color correction and enhancement for underwater images is challenging due to attenuation and scattering. The underwater images often have low visibility and suffer from color bias. This paper presents a novel color correction method based on color filter array (CFA) and an enhancement method based on Retinex with dense pixels and adaptive linear histogram transformation for degraded color-biased underwater images. For any digital image in the RGB space, which is captured by digital camera with CFA, their RGB values are dependent and coupled because of the interpolation process. So we try to compensate red channel attenuation of underwater degraded images from the green channel and blue channel. Retinex model has been widely used to efficiently handle low brightness and blurred images. The McCann Retinex (MR) method selects a spiral path for pixel comparison to estimate illumination. However, the simple path selection doesnâ€™t include global light dark relationship of the whole image. So we design a scheme to gain much well-distributed and denser pixels to obtain more precise intensity of illumination. Besides, we design a piecewise linear function for histogram transform, which is adaptive to the whole RGB value. Experiments on a large number of underwater degraded images show that, the processed images by our method have clearer details and uniform visual effect for all channels in RGB color space and our method can also obtain good performance metrics.}
}
@article{Panetta_2021,
  title    = {Comprehensive Underwater Object Tracking Benchmark Dataset and Underwater Image Enhancement With GAN},
  year     = {2021},
  author   = {Karen Panetta and Karen Panetta and Landry Kezebou and Landry Kezebou and Victor Oludare and Victor Oludare and Sos S. Agaian and Sos S. Agaian},
  doi      = {10.1109/joe.2021.3086907},
  pmid     = {null},
  pmcid    = {null},
  mag_id   = {3183339502},
  journal  = {IEEE Journal of Oceanic Engineering},
  abstract = {Current state-of-the-art object tracking methods have largely benefited from the public availability of numerous benchmark datasets. However, the focus has been on open-air imagery and much less on underwater visual data. Inherent underwater distortions, such as color loss, poor contrast, and underexposure, caused by attenuation of light, refraction, and scattering, greatly affect the visual quality of underwater data, and as such, existing open-air trackers perform less efficiently on such data. To help bridge this gap, this article proposes a first comprehensive underwater object tracking (UOT100) benchmark dataset to facilitate the development of tracking algorithms well-suited for underwater environments. The proposed dataset consists of 104 underwater video sequences and more than 74000 annotated frames derived from both natural and artificial underwater videos, with great varieties of distortions. We benchmark the performance of 20 state-of-the-art object tracking algorithms and further introduce a cascaded residual network for underwater image enhancement model to improve tracking accuracy and success rate of trackers. Our experimental results demonstrate the shortcomings of existing tracking algorithms on underwater data and how our generative adversarial network (GAN)-based enhancement model can be used to improve tracking performance. We also evaluate the visual quality of our model's output against existing GAN-based methods using well-accepted quality metrics and demonstrate that our model yields better visual data.}
}
@article{Fayaz_2023,
  title    = {Intelligent Underwater Object Detection and Image Restoration for Autonomous Underwater Vehicles},
  year     = {2023},
  author   = {Sheezan Fayaz and Shabir A. Parah and G. J. Qureshi and Jaime Lloret and Javier Del Ser and Khan Muhammad},
  doi      = {10.1109/tvt.2023.3318629},
  pmid     = {null},
  pmcid    = {null},
  mag_id   = {4387010722},
  journal  = {IEEE Transactions on Vehicular Technology},
  abstract = {Unmanned Underwater Vehicles (UUVs) have been reliable and economical technological solutions to perform undersea monitoring tasks in comparison to manned vehicles. However, in many situations, UUV is unable to fulfill complex undersea research tasks since target objects appear distorted due to light absorption and scattering. Besides, ocean surveying undergoes severe power requirements compared to terrestrial systems because of battery-driven low-storage vehicles like Unmanned Underwater Vehicles (UUVs). Therefore, limited power supply, motion resistance of water medium, and distorted target object appearance can delay the mission and reduce the efficiency of UUV in their underwater operations. Considering the resource-constrained undersea monitoring setup, we propose an intelligent two-stage framework for expeditious monitoring of underwater scenes. First, an effective deep neural network is employed for underwater object/region of interest (ROI) detection. Then the detected ROI is restored using an efficient restoration method, thereby improving the visual quality of the degraded images and aiding the navigating and monitoring tasks of UUVs. Our method has been objectively and subjectively assessed using 9 evaluation metrics and our key results reveal mAP of 94.35% and an Underwater Color Image Quality Evaluation (UCIQE) score of 3.09, surpassing state-of-the-art methods for object detection. Furthermore, the execution time of 0.550 secs is required for object detection and dehazing, making this proposal suitable for UUVs to perform automatic undersea object detection and dehazing within operational running requirements.}
}
@article{Saleem_2023,
  title    = {A Non-Reference Evaluation of Underwater Image Enhancement Methods Using a New Underwater Image Dataset},
  year     = {2023},
  author   = {Ashraf Saleem and Paheding Sidike and Nathir A. Rawashdeh and Ali Ismail Awad and Navjot Kaur},
  doi      = {10.1109/access.2023.3240648},
  pmid     = {null},
  pmcid    = {null},
  mag_id   = {4318586155},
  journal  = {IEEE Access},
  abstract = {The rise of vision-based environmental, marine, and oceanic exploration research highlights the need for supporting underwater image enhancement techniques to help mitigate water effects on images such as blurriness, low color contrast, and poor quality. This paper presents an evaluation of common underwater image enhancement techniques using our new publicly-available Challenging Dataset for Underwater Image Enhancement (CDUIE). The collected dataset is comprised of 85 images of aquatic plants taken at a shallow depth of up to three meters from three different locations in the Great Lake Superior, USA, via a Remotely Operated Vehicle (ROV) equipped with a high-definition RGB camera. In particular, we use our dataset to benchmark nine state-of-the-art image enhancement models at three different depths using a set of common non-reference image quality evaluation metrics. Then we provide a comparative analysis of the performance of the selected models at different depths and highlight the most prevalent ones. The obtained results show that the selected image enhancement models are capable of producing considerably better-quality images with some models performing better than others at certain depths. The dataset is available at <uri xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">https://www.github.com/ashrafrepo/underwater-image-enhancement</uri> .}
}
@article{Li_2021,
  title    = {Underwater Image Enhancement via Medium Transmission-Guided Multi-Color Space Embedding},
  year     = {2021},
  author   = {Chongyi Li and Chongyi Li and Saeed Anwar and Saeed Anwar and Junhui Hou and Junhui Hou and Runmin Cong and Runmin Cong and Chunle Guo and Chunle Guo and Wenqi Ren and Wenqi Ren},
  doi      = {10.1109/tip.2021.3076367},
  pmid     = {33961554},
  pmcid    = {null},
  mag_id   = {3159660641},
  journal  = {IEEE Transactions on Image Processing},
  abstract = {Underwater images suffer from color casts and low contrast due to wavelength-and distance-dependent attenuation and scattering. To solve these two degradation issues, we present an underwater image enhancement network via medium transmission-guided multi-color space embedding, called Ucolor. Concretely, we first propose a multi-color space encoder network, which enriches the diversity of feature representations by incorporating the characteristics of different color spaces into a unified structure. Coupled with an attention mechanism, the most discriminative features extracted from multiple color spaces are adaptively integrated and highlighted. Inspired by underwater imaging physical models, we design a medium transmission (indicating the percentage of the scene radiance reaching the camera)-guided decoder network to enhance the response of network towards quality-degraded regions. As a result, our network can effectively improve the visual quality of underwater images by exploiting multiple color spaces embedding and the advantages of both physical model-based and learning-based methods. Extensive experiments demonstrate that our Ucolor achieves superior performance against state-of-the-art methods in terms of both visual quality and quantitative metrics. The code is publicly available at.}
}
@article{Peng_2022,
  title    = {Underwater Image Enhancement Based on Histogram-Equalization Approximation Using Physics-Based Dichromatic Modeling.},
  year     = {2022},
  author   = {Yan-Tsung Peng and Yan-Tsung Peng and Yen-Rong Chen and Yen-Rong Chen and Zihao Chen and Zihao Chen and Jung-Hua Wang and Jung-Hua Wang and Shih-Chia Huang and Shih-Chia Huang},
  doi      = {10.3390/s22062168},
  pmid     = {35336336},
  pmcid    = {8953322},
  mag_id   = {4220815208},
  journal  = {Sensors},
  abstract = {This work proposes to develop an underwater image enhancement method based on histogram-equalization (HE) approximation using physics-based dichromatic modeling (PDM). Images captured underwater usually suffer from low contrast and color distortions due to light scattering and attenuation. The PDM describes the image formation process, which can be used to restore nature-degraded images, such as underwater images. However, it does not assure that the restored images have good contrast. Thus, we propose approximating the conventional HE based on the PDM to recover the color distortions of underwater images and enhance their contrast through convex optimization. Experimental results demonstrate the proposed method performs favorably against state-of-the-art underwater image restoration approaches.}
}
@article{Yuan_2025,
  title    = {IGFU: A Hybrid Underwater Image Enhancement Approach Combining Adaptive GWA, FFA-Net With USM},
  year     = {2025},
  author   = {Xin Yuan and Chenhui Wang and Xiaohong Chen and Mingxuan Wang and Ning Li and Changli Yu},
  doi      = {10.1109/ojcs.2024.3492698},
  pmid     = {null},
  pmcid    = {null},
  mag_id   = {null},
  journal  = {IEEE Open Journal of the Computer Society},
  abstract = {To address the issue of color distortion and blurriness in underwater imageries, a hybrid Underwater Image Enhancement (UIE) method combining Adaptive Gray World Algorithm (GWA), Feature Fusion Attention Network (FFA-Net) and Unsharp Masking (USM) is proposed in this research. This method begins with color correction by applying different stretching processes to the RGB components based on the image's color information, and iteratively corrects the colors. Next, the corrected image undergoes dehazing via FFA-Net to eliminate underwater haze and improve clarity. Ultimately, USM is applied to amplify high-frequency components, thus enhancing edge details. Qualitative and quantitative comparisons demonstrate that the proposed Improved GWA FFA-Net USM (IGFU) method outperforms existing techniques in underwater image quality.}
}
@article{Wu_2021,
  title    = {A Two-Stage Underwater Enhancement Network Based on Structure Decomposition and Characteristics of Underwater Imaging},
  year     = {2021},
  author   = {Shengcong Wu and Shengcong Wu and Ting Luo and Ting Luo and Gangyi Jiang and Jiang Gangyi and Gangyi Jiang and Mei Yu and Mei Yu and Mei Yu and Haiyong Xu and Haiyong Xu and Zhongkui Zhu and Zhongjie Zhu and Zhongjie Zhu and Yang Song and Yang Song},
  doi      = {10.1109/joe.2021.3064093},
  pmid     = {null},
  pmcid    = {null},
  mag_id   = {3159377007},
  journal  = {IEEE Journal of Oceanic Engineering},
  abstract = {Due to the scattering and attenuation of light into the water, the underwater image usually appears with color distortion, blurred details, and low contrast. To address these problems, a novel two-stage underwater image convolutional neural network (CNN) based on structure decomposition (UWCNN-SD) for underwater image enhancement is proposed by considering the characteristics of underwater imaging. Specifically, the raw underwater image is decomposed into high-frequency and low-frequency based on theoretical analysis of the underwater imaging. Then, a two-stage underwater enhancement network including a preliminary enhancement network and a refinement network is proposed. In the first stage, the preliminary enhancement network, which contains the high-frequency and the low-frequency enhancement networks, is proposed. The high-frequency part is enhanced directly by a deep learning network, and the low-frequency enhancement network is based on the underwater imaging, which is integrated transmission map and background light into joint component map. In the second stage, the refinement network is designed to further optimize the color of the underwater image by considering complexity of underwater imaging. The experimental results of synthetic and real-world underwater images/videos demonstrate that the proposed UWCNN-SD method can perform color correction and enhancement on different types of underwater images. The ablation study verifies the effectiveness of each component, and application tests further illustrate that the proposed UWCNN-SD method can obtain underwater images with higher visual quality. The trained model is available at: https://github.com/wushengcong/UWCNN-SD.}
}
